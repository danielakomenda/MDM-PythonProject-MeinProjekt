{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59665da-e6c8-44b2-9f5a-db28f1eb4c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import datetime\n",
    "import os\n",
    "import dotenv\n",
    "import re\n",
    "import json\n",
    "\n",
    "import pymongo\n",
    "import httpx\n",
    "import bs4\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34b86bb5-9c9d-41f8-935d-954fb88ec438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db():\n",
    "    \"\"\"Open the connection to the DB and return the collection\n",
    "    Create collection with unique index, if there is not yet one\"\"\"\n",
    "    # Load environment variables from .env file\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get MongoDB-URI\n",
    "    mongodb_uri = os.getenv(\"MONGODB_URI\")\n",
    "    DBclient = pymongo.MongoClient(mongodb_uri)\n",
    "    db = DBclient[\"MDM-Python-MeinProjekt\"]\n",
    "\n",
    "    if \"Energie\" in db.list_collection_names():\n",
    "        return db[\"Energie\"]\n",
    "    else:\n",
    "        collection = db[\"Energie\"]\n",
    "        collection.create_index([\n",
    "            (\"country\", pymongo.ASCENDING),\n",
    "            (\"datetime\", pymongo.ASCENDING),\n",
    "        ], unique=True)\n",
    "        return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aee47f3-41ef-4091-88c7-f541c8cdc32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_website_data(country, date) -> pd.DataFrame:\n",
    "    \"\"\"Access the website with the needed parameters; return a PandasDataFrame\"\"\"\n",
    "    \n",
    "    # Create List with all 20 Productions-Types\n",
    "    productiontypes = [\n",
    "        (\"productionType.values\", f\"B{k:02}\") for k in range(1, 21)\n",
    "    ]\n",
    "    \n",
    "        \n",
    "    async with httpx.AsyncClient() as client:\n",
    "        result = await client.get(\n",
    "            url=\"https://transparency.entsoe.eu/generation/r2/actualGenerationPerProductionType/show\",\n",
    "            headers={\n",
    "                \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "            },\n",
    "            params=list(\n",
    "                {\n",
    "                    \"viewType\": \"GRAPH\",\n",
    "                    \"areaType\": \"CTY\",\n",
    "                    \"dateTime.dateTime\": f\"{date:%d.%m.%Y} 00:00|UTC|DAYTIMERANGE\",\n",
    "                    \"dateTime.endDateTime\": f\"{date:%d.%m.%Y} 00:00|UTC|DAYTIMERANGE\",\n",
    "                    \"dateTime.timezone\": \"UTC\",\n",
    "                    \"area.values\": f\"CTY|{country}!CTY|{country}\",\n",
    "                }.items()) + productiontypes,\n",
    "            )\n",
    "            \n",
    "    # make sure the content is UTF-8 and parse the content with bs4\n",
    "    assert result.headers[\"content-type\"] == \"text/html;charset=UTF-8\", result.headers[\"content-type\"]\n",
    "    soup = bs4.BeautifulSoup(result.content.decode(\"utf-8\"))\n",
    "    \n",
    "    # select only the part 'script' and the chart-list of the http-file\n",
    "    javascript_str = soup.find(\"script\").text\n",
    "    match = re.search(r\"var\\s+chart\\s*=\\s*({.*})\\s*;\", javascript_str, re.S)\n",
    "    assert match is not None\n",
    "    \n",
    "    # returns the first element of the group\n",
    "    data = json.loads(match.group(1))\n",
    "    \n",
    "    # defines the columns for the dataframe\n",
    "    columns = {\n",
    "        k: \" \".join(v[\"title\"].split())\n",
    "        for k, v in\n",
    "        data[\"graphDesign\"].items()\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        data[\"chartData\"]\n",
    "    ).set_index(data[\"categoryName\"]).astype(float).rename(columns=columns)\n",
    "    \n",
    "    # combine time with date to get a real timestamp\n",
    "    df = df.set_index(pd.MultiIndex.from_arrays(\n",
    "        [\n",
    "            [country]*df.shape[0],\n",
    "            df.index.to_series().apply(\n",
    "                lambda v: datetime.datetime.combine(date, datetime.time.fromisoformat(v))\n",
    "            ).dt.tz_localize(\"UTC\"),\n",
    "        ],\n",
    "        names=[\"country\", \"datetime\"],\n",
    "    ))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e09b9d47-e477-4115-9d52-cb412362e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_to_db(collection, df):\n",
    "    \"\"\"Insert the data to the collection; if there is already a data-set with the same location and time,\n",
    "    an Error is raised, but the rest of the inserts will carry on\"\"\"\n",
    "\n",
    "    data = df.reset_index().to_dict(\"records\")\n",
    "\n",
    "    collection.insert_many(\n",
    "        data,\n",
    "        ordered=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3399520-98ae-4951-840a-e7d80f7b8daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scraping():\n",
    "    \"\"\"Run the program: Scraping the website, Insert it to DB\"\"\"\n",
    "\n",
    "    collection = connect_to_db()\n",
    "    end_date = datetime.date.today() - datetime.timedelta(days=1)\n",
    "    start_date = end_date - datetime.timedelta(days=365)\n",
    "    country = \"10YCH-SWISSGRIDZ\"\n",
    "    \n",
    "    date = pd.date_range(start_date, end_date, freq=\"D\")\n",
    "\n",
    "    collected_dfs = []\n",
    "    \n",
    "    for d in date:\n",
    "        print(f'Working on {d.year}-{d.month}-{d.day}')\n",
    "        df = await scrape_website_data(country=country, date=d)\n",
    "        collected_dfs.append(df)\n",
    "            \n",
    "    df_to_insert = pd.concat(collected_dfs)  \n",
    "\n",
    "    print(\"all data scraped, ready to insert in db\")\n",
    "    \n",
    "    try:\n",
    "        insert_data_to_db(collection, df_to_insert)\n",
    "    except pymongo.errors.BulkWriteError as ex:\n",
    "        result = dict(ex.details)\n",
    "        write_errors = result.pop(\"writeErrors\",[])\n",
    "        ok = all(err.get(\"code\") == 11000 for err in write_errors)\n",
    "        ok = ok and not result.get(\"writeConcernErrors\")\n",
    "        n_success = result['nInserted']\n",
    "        n_duplicate = len(write_errors)\n",
    "        ok = ok and (n_success + n_duplicate) == df_to_insert.shape[0]\n",
    "        if ok:\n",
    "            print(f\"Discarded {n_duplicate} inserts due to duplicate keys, inserted {n_success} documents.\")\n",
    "        else:\n",
    "            had_write_concern = len(result.get(\"writeConcernErrors\",[]))\n",
    "            not_discarded = sum(err.get(\"code\") != 11000 for err in write_errors)\n",
    "            raise RuntimeError(f\"Unexpected error; {n_duplicate=} {n_success=} {df_to_insert.shape[0]=} {had_write_concern=} {not_discarded=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f98764a1-70b4-462a-ac96-0d149a5009a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 2023-3-10\n",
      "Working on 2023-3-11\n",
      "Working on 2023-3-12\n",
      "Working on 2023-3-13\n",
      "Working on 2023-3-14\n",
      "Working on 2023-3-15\n",
      "Working on 2023-3-16\n",
      "Working on 2023-3-17\n",
      "Working on 2023-3-18\n",
      "Working on 2023-3-19\n",
      "Working on 2023-3-20\n",
      "Working on 2023-3-21\n",
      "Working on 2023-3-22\n",
      "Working on 2023-3-23\n",
      "Working on 2023-3-24\n",
      "Working on 2023-3-25\n",
      "Working on 2023-3-26\n",
      "Working on 2023-3-27\n",
      "Working on 2023-3-28\n",
      "Working on 2023-3-29\n",
      "Working on 2023-3-30\n",
      "Working on 2023-3-31\n",
      "Working on 2023-4-1\n",
      "Working on 2023-4-2\n",
      "Working on 2023-4-3\n",
      "Working on 2023-4-4\n",
      "Working on 2023-4-5\n",
      "Working on 2023-4-6\n",
      "Working on 2023-4-7\n",
      "Working on 2023-4-8\n",
      "Working on 2023-4-9\n",
      "Working on 2023-4-10\n",
      "Working on 2023-4-11\n",
      "Working on 2023-4-12\n",
      "Working on 2023-4-13\n",
      "Working on 2023-4-14\n",
      "Working on 2023-4-15\n",
      "Working on 2023-4-16\n",
      "Working on 2023-4-17\n",
      "Working on 2023-4-18\n",
      "Working on 2023-4-19\n",
      "Working on 2023-4-20\n",
      "Working on 2023-4-21\n",
      "Working on 2023-4-22\n",
      "Working on 2023-4-23\n",
      "Working on 2023-4-24\n",
      "Working on 2023-4-25\n",
      "Working on 2023-4-26\n",
      "Working on 2023-4-27\n",
      "Working on 2023-4-28\n",
      "Working on 2023-4-29\n",
      "Working on 2023-4-30\n",
      "Working on 2023-5-1\n",
      "Working on 2023-5-2\n",
      "Working on 2023-5-3\n",
      "Working on 2023-5-4\n",
      "Working on 2023-5-5\n",
      "Working on 2023-5-6\n",
      "Working on 2023-5-7\n",
      "Working on 2023-5-8\n",
      "Working on 2023-5-9\n",
      "Working on 2023-5-10\n",
      "Working on 2023-5-11\n",
      "Working on 2023-5-12\n",
      "Working on 2023-5-13\n",
      "Working on 2023-5-14\n",
      "Working on 2023-5-15\n",
      "Working on 2023-5-16\n",
      "Working on 2023-5-17\n",
      "Working on 2023-5-18\n",
      "Working on 2023-5-19\n",
      "Working on 2023-5-20\n",
      "Working on 2023-5-21\n",
      "Working on 2023-5-22\n",
      "Working on 2023-5-23\n",
      "Working on 2023-5-24\n",
      "Working on 2023-5-25\n",
      "Working on 2023-5-26\n",
      "Working on 2023-5-27\n",
      "Working on 2023-5-28\n",
      "Working on 2023-5-29\n",
      "Working on 2023-5-30\n",
      "Working on 2023-5-31\n",
      "Working on 2023-6-1\n",
      "Working on 2023-6-2\n",
      "Working on 2023-6-3\n",
      "Working on 2023-6-4\n",
      "Working on 2023-6-5\n",
      "Working on 2023-6-6\n",
      "Working on 2023-6-7\n",
      "Working on 2023-6-8\n",
      "Working on 2023-6-9\n",
      "Working on 2023-6-10\n",
      "Working on 2023-6-11\n",
      "Working on 2023-6-12\n",
      "Working on 2023-6-13\n",
      "Working on 2023-6-14\n",
      "Working on 2023-6-15\n",
      "Working on 2023-6-16\n",
      "Working on 2023-6-17\n",
      "Working on 2023-6-18\n",
      "Working on 2023-6-19\n",
      "Working on 2023-6-20\n",
      "Working on 2023-6-21\n",
      "Working on 2023-6-22\n",
      "Working on 2023-6-23\n",
      "Working on 2023-6-24\n",
      "Working on 2023-6-25\n",
      "Working on 2023-6-26\n",
      "Working on 2023-6-27\n",
      "Working on 2023-6-28\n",
      "Working on 2023-6-29\n",
      "Working on 2023-6-30\n",
      "Working on 2023-7-1\n",
      "Working on 2023-7-2\n",
      "Working on 2023-7-3\n",
      "Working on 2023-7-4\n",
      "Working on 2023-7-5\n",
      "Working on 2023-7-6\n",
      "Working on 2023-7-7\n",
      "Working on 2023-7-8\n",
      "Working on 2023-7-9\n",
      "Working on 2023-7-10\n",
      "Working on 2023-7-11\n",
      "Working on 2023-7-12\n",
      "Working on 2023-7-13\n",
      "Working on 2023-7-14\n",
      "Working on 2023-7-15\n",
      "Working on 2023-7-16\n",
      "Working on 2023-7-17\n",
      "Working on 2023-7-18\n",
      "Working on 2023-7-19\n",
      "Working on 2023-7-20\n",
      "Working on 2023-7-21\n",
      "Working on 2023-7-22\n",
      "Working on 2023-7-23\n",
      "Working on 2023-7-24\n",
      "Working on 2023-7-25\n",
      "Working on 2023-7-26\n",
      "Working on 2023-7-27\n",
      "Working on 2023-7-28\n",
      "Working on 2023-7-29\n",
      "Working on 2023-7-30\n",
      "Working on 2023-7-31\n",
      "Working on 2023-8-1\n",
      "Working on 2023-8-2\n",
      "Working on 2023-8-3\n",
      "Working on 2023-8-4\n",
      "Working on 2023-8-5\n",
      "Working on 2023-8-6\n",
      "Working on 2023-8-7\n",
      "Working on 2023-8-8\n",
      "Working on 2023-8-9\n",
      "Working on 2023-8-10\n",
      "Working on 2023-8-11\n",
      "Working on 2023-8-12\n",
      "Working on 2023-8-13\n",
      "Working on 2023-8-14\n",
      "Working on 2023-8-15\n",
      "Working on 2023-8-16\n",
      "Working on 2023-8-17\n",
      "Working on 2023-8-18\n",
      "Working on 2023-8-19\n",
      "Working on 2023-8-20\n",
      "Working on 2023-8-21\n",
      "Working on 2023-8-22\n",
      "Working on 2023-8-23\n",
      "Working on 2023-8-24\n",
      "Working on 2023-8-25\n",
      "Working on 2023-8-26\n",
      "Working on 2023-8-27\n",
      "Working on 2023-8-28\n",
      "Working on 2023-8-29\n",
      "Working on 2023-8-30\n",
      "Working on 2023-8-31\n",
      "Working on 2023-9-1\n",
      "Working on 2023-9-2\n",
      "Working on 2023-9-3\n",
      "Working on 2023-9-4\n",
      "Working on 2023-9-5\n",
      "Working on 2023-9-6\n",
      "Working on 2023-9-7\n",
      "Working on 2023-9-8\n",
      "Working on 2023-9-9\n",
      "Working on 2023-9-10\n",
      "Working on 2023-9-11\n",
      "Working on 2023-9-12\n",
      "Working on 2023-9-13\n",
      "Working on 2023-9-14\n",
      "Working on 2023-9-15\n",
      "Working on 2023-9-16\n",
      "Working on 2023-9-17\n",
      "Working on 2023-9-18\n",
      "Working on 2023-9-19\n",
      "Working on 2023-9-20\n",
      "Working on 2023-9-21\n",
      "Working on 2023-9-22\n",
      "Working on 2023-9-23\n",
      "Working on 2023-9-24\n",
      "Working on 2023-9-25\n",
      "Working on 2023-9-26\n",
      "Working on 2023-9-27\n",
      "Working on 2023-9-28\n",
      "Working on 2023-9-29\n",
      "Working on 2023-9-30\n",
      "Working on 2023-10-1\n",
      "Working on 2023-10-2\n",
      "Working on 2023-10-3\n",
      "Working on 2023-10-4\n",
      "Working on 2023-10-5\n",
      "Working on 2023-10-6\n",
      "Working on 2023-10-7\n",
      "Working on 2023-10-8\n",
      "Working on 2023-10-9\n",
      "Working on 2023-10-10\n",
      "Working on 2023-10-11\n",
      "Working on 2023-10-12\n",
      "Working on 2023-10-13\n",
      "Working on 2023-10-14\n",
      "Working on 2023-10-15\n",
      "Working on 2023-10-16\n",
      "Working on 2023-10-17\n",
      "Working on 2023-10-18\n",
      "Working on 2023-10-19\n",
      "Working on 2023-10-20\n",
      "Working on 2023-10-21\n",
      "Working on 2023-10-22\n",
      "Working on 2023-10-23\n",
      "Working on 2023-10-24\n",
      "Working on 2023-10-25\n",
      "Working on 2023-10-26\n",
      "Working on 2023-10-27\n",
      "Working on 2023-10-28\n",
      "Working on 2023-10-29\n",
      "Working on 2023-10-30\n",
      "Working on 2023-10-31\n",
      "Working on 2023-11-1\n",
      "Working on 2023-11-2\n",
      "Working on 2023-11-3\n",
      "Working on 2023-11-4\n",
      "Working on 2023-11-5\n",
      "Working on 2023-11-6\n",
      "Working on 2023-11-7\n",
      "Working on 2023-11-8\n",
      "Working on 2023-11-9\n",
      "Working on 2023-11-10\n",
      "Working on 2023-11-11\n",
      "Working on 2023-11-12\n",
      "Working on 2023-11-13\n",
      "Working on 2023-11-14\n",
      "Working on 2023-11-15\n",
      "Working on 2023-11-16\n",
      "Working on 2023-11-17\n",
      "Working on 2023-11-18\n",
      "Working on 2023-11-19\n",
      "Working on 2023-11-20\n",
      "Working on 2023-11-21\n",
      "Working on 2023-11-22\n",
      "Working on 2023-11-23\n",
      "Working on 2023-11-24\n",
      "Working on 2023-11-25\n",
      "Working on 2023-11-26\n",
      "Working on 2023-11-27\n",
      "Working on 2023-11-28\n",
      "Working on 2023-11-29\n",
      "Working on 2023-11-30\n",
      "Working on 2023-12-1\n",
      "Working on 2023-12-2\n",
      "Working on 2023-12-3\n",
      "Working on 2023-12-4\n",
      "Working on 2023-12-5\n",
      "Working on 2023-12-6\n",
      "Working on 2023-12-7\n",
      "Working on 2023-12-8\n",
      "Working on 2023-12-9\n",
      "Working on 2023-12-10\n",
      "Working on 2023-12-11\n",
      "Working on 2023-12-12\n",
      "Working on 2023-12-13\n",
      "Working on 2023-12-14\n",
      "Working on 2023-12-15\n",
      "Working on 2023-12-16\n",
      "Working on 2023-12-17\n",
      "Working on 2023-12-18\n",
      "Working on 2023-12-19\n",
      "Working on 2023-12-20\n",
      "Working on 2023-12-21\n",
      "Working on 2023-12-22\n",
      "Working on 2023-12-23\n",
      "Working on 2023-12-24\n",
      "Working on 2023-12-25\n",
      "Working on 2023-12-26\n",
      "Working on 2023-12-27\n",
      "Working on 2023-12-28\n",
      "Working on 2023-12-29\n",
      "Working on 2023-12-30\n",
      "Working on 2023-12-31\n",
      "Working on 2024-1-1\n",
      "Working on 2024-1-2\n",
      "Working on 2024-1-3\n",
      "Working on 2024-1-4\n",
      "Working on 2024-1-5\n",
      "Working on 2024-1-6\n",
      "Working on 2024-1-7\n",
      "Working on 2024-1-8\n",
      "Working on 2024-1-9\n",
      "Working on 2024-1-10\n",
      "Working on 2024-1-11\n",
      "Working on 2024-1-12\n",
      "Working on 2024-1-13\n",
      "Working on 2024-1-14\n",
      "Working on 2024-1-15\n",
      "Working on 2024-1-16\n",
      "Working on 2024-1-17\n",
      "Working on 2024-1-18\n",
      "Working on 2024-1-19\n",
      "Working on 2024-1-20\n",
      "Working on 2024-1-21\n",
      "Working on 2024-1-22\n",
      "Working on 2024-1-23\n",
      "Working on 2024-1-24\n",
      "Working on 2024-1-25\n",
      "Working on 2024-1-26\n",
      "Working on 2024-1-27\n",
      "Working on 2024-1-28\n",
      "Working on 2024-1-29\n",
      "Working on 2024-1-30\n",
      "Working on 2024-1-31\n",
      "Working on 2024-2-1\n",
      "Working on 2024-2-2\n",
      "Working on 2024-2-3\n",
      "Working on 2024-2-4\n",
      "Working on 2024-2-5\n",
      "Working on 2024-2-6\n",
      "Working on 2024-2-7\n",
      "Working on 2024-2-8\n",
      "Working on 2024-2-9\n",
      "Working on 2024-2-10\n",
      "Working on 2024-2-11\n",
      "Working on 2024-2-12\n",
      "Working on 2024-2-13\n",
      "Working on 2024-2-14\n",
      "Working on 2024-2-15\n",
      "Working on 2024-2-16\n",
      "Working on 2024-2-17\n",
      "Working on 2024-2-18\n",
      "Working on 2024-2-19\n",
      "Working on 2024-2-20\n",
      "Working on 2024-2-21\n",
      "Working on 2024-2-22\n",
      "Working on 2024-2-23\n",
      "Working on 2024-2-24\n",
      "Working on 2024-2-25\n",
      "Working on 2024-2-26\n",
      "Working on 2024-2-27\n",
      "Working on 2024-2-28\n",
      "Working on 2024-2-29\n",
      "Working on 2024-3-1\n",
      "Working on 2024-3-2\n",
      "Working on 2024-3-3\n",
      "Working on 2024-3-4\n",
      "Working on 2024-3-5\n",
      "Working on 2024-3-6\n",
      "Working on 2024-3-7\n",
      "Working on 2024-3-8\n",
      "Working on 2024-3-9\n",
      "all data scraped, ready to insert in db\n",
      "Discarded 192 inserts due to duplicate keys, inserted 8568 documents.\n"
     ]
    }
   ],
   "source": [
    "await scraping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634088af-8a6b-40ce-86a2-be4ff6c7b358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341c406-b0bc-4e78-a468-a6748dff5536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
