{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59665da-e6c8-44b2-9f5a-db28f1eb4c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "import pymongo\n",
    "import httpx\n",
    "import bs4\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b86bb5-9c9d-41f8-935d-954fb88ec438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db_Wetter():\n",
    "    # Load environment variables from .env file\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get MongoDB-URI\n",
    "    mongodb_uri = os.getenv(\"MONGODB_URI\")\n",
    "    DBclient = pymongo.MongoClient(mongodb_uri)\n",
    "    db = DBclient[\"MDM-Python-MeinProjekt\"]\n",
    "\n",
    "    if \"Wetter\" in db.list_collection_names():\n",
    "        return db[\"Wetter\"]\n",
    "    else:\n",
    "        collection = db[\"Wetter\"]\n",
    "        collection.create_index([\n",
    "            (\"location\", pymongo.ASCENDING),\n",
    "            (\"datetime\", pymongo.ASCENDING),\n",
    "        ], unique=True)\n",
    "        return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b3a7758-0c64-46fc-a0fc-60f5abe6203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db_Wetter_Durchschnitt():\n",
    "    # Load environment variables from .env file\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get MongoDB-URI\n",
    "    mongodb_uri = os.getenv(\"MONGODB_URI\")\n",
    "    DBclient = pymongo.MongoClient(mongodb_uri)\n",
    "    db = DBclient[\"MDM-Python-MeinProjekt\"]\n",
    "\n",
    "    if \"Wetter_Durchschnitt\" in db.list_collection_names():\n",
    "        return db[\"Wetter_Durchschnitt\"]\n",
    "    else:\n",
    "        collection = db[\"Wetter_Durchschnitt\"]\n",
    "        collection.create_index([\n",
    "            (\"date\", pymongo.ASCENDING),\n",
    "        ], unique=True)\n",
    "        return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0441ab78-6389-4a7a-986a-130739942955",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.date.today() - datetime.timedelta(days=670) #670\n",
    "start_date = end_date - datetime.timedelta(days=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8dbcca-20fd-4a97-9e0c-e658f5134466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 36 Locations in Switzerland\n",
    "locations = {\n",
    "    \"Aarau,Switzerland\": \"5a5ecc58df562835e3fcbae5f8c52e64e7247918\",\n",
    "    \"Appenzell,Switzerland\": \"162a2967db482d9de5e1db7b98c7fa5a779f2875\",\n",
    "    \"Basel,Switzerland\": \"e502a0a8fc421e6a8f9f1c4034f6b46ff6f59f62\",\n",
    "    \"Bellinzona,Switzerland\": \"f398035eff9921de0368cc494578468b1d5c99ad\",\n",
    "    \"Bern,Switzerland\": \"94fa2a5396a4723b31142ab413d3ec1be77d62d8\",\n",
    "    \"Chur,Switzerland\": \"6c0da286ee836415b66b138d6f13076fbcdb3899\",\n",
    "    \"Davos,Switzerland\": \"e260b1b791f27abac6a4f7771a2401be6aee67a9\",\n",
    "    \"Delemont,Switzerland\": \"f661d8d34fbb2431d6f02a9613c09a3782655d55\",\n",
    "    \"Einsiedeln,Switzerland\": \"14ee1f6a8ff571616de7f378af94b0a588c67bda\",\n",
    "    \"Frauenfeld,Switzerland\": \"8bf573628b0fd96382f03bef84c063f3aa481e21\",\n",
    "    \"Fribourg,Switzerland\": \"f5240fc4fcffbe2c1680ee6f026349a7c2c0da48\",\n",
    "    \"Geneva,Switzerland\": \"eacb20159164fa15c55f87d7d66068b4b2ceaf39\",\n",
    "    \"Glarus,Switzerland\": \"dcb4a71fe438a4165ee26a4d370d259a2c5896d0\",\n",
    "    \"Grindelwald,Switzerland\": \"ab1c057337ed2fca115ed0e16b4ec2467466aaad\",\n",
    "    \"La_Chaux_De_Fonds,Switzerland\": \"d78dc7da556213f33175d58cc6d1de8534ac3a6c\",\n",
    "    \"Laax,Switzerland\": \"eb8dfc2322338b344ef7f8f1063e01f91b555137\",\n",
    "    \"Lausanne,Switzerland\": \"fb15d1e5d748ce024a944f59f9bf651919032bd1\",\n",
    "    \"Lauterbrunnen,Switzerland\": \"8a9e5db01b10728c85ac4944d19e79e515f3deba\",\n",
    "    \"Lenzerheide,Switzerland\": \"73330944ee4dbe329e5f8cfbf7bc49a0f420ba2f\",\n",
    "    \"Leukerbad,Switzerland\": \"7d2f2e013101f38faf031a38c5d9b348aeb883e3\",\n",
    "    \"Lucerne,Switzerland\": \"470964fac0430b6083c52ddd3e2a400c542e0e60\",\n",
    "    \"Lugano,Switzerland\": \"f9bc6e13323ac7547a608fa227ff7e274284d1f2\",\n",
    "    \"Montreux,Switzerland\": \"0034c59b5b977acd17fe5837e5845ae9f41e5a09\",\n",
    "    \"Neuchatel,Switzerland\": \"684590561854da6d27a36d9e659cc4739f675b1c\",\n",
    "    \"Romanshorn,Switzerland\": \"39fe927062dc9f07e6b3abed0189caf29b9745fd\",\n",
    "    \"Saas_Fee,Switzerland\": \"865c64f03112f377ad70f301a218110eefa322b8\",\n",
    "    \"Sarnen,Switzerland\": \"8a7c9fe3ae4cbce26ca0d3447542641f60ef781c\",\n",
    "    \"Savognin,Switzerland\": \"8bb604df8ccd428e2f37e5c4239c93f4dc55f19f\",\n",
    "    \"Schaffhausen,Switzerland\": \"8b5f38ff71ef8dcc2b857f39361149bb6193e4c3\",\n",
    "    \"Sion,Switzerland\": \"f092059ab917cc1a9a335215a1f4744944feaec3\",\n",
    "    \"Solothurn,Switzerland\": \"a6e3ca1b9fedf679fcc41159f5f5a56a58ca7354\",\n",
    "    \"St_Gallen,Switzerland\": \"c6a7895be45659cd932d951b975b522d5964f9af\",\n",
    "    \"Tenero,Switzerland\": \"cb4313847fec5d64e08e0549340a914da569db0f\",\n",
    "    \"Thun,Switzerland\": \"4e567234358d307fb77c5cb5514150df3cd59a3c\",\n",
    "    \"Verbier,Switzerland\": \"d9ab4f99f16929d6a5dea4a9b3f20d60af8dd3f9\",\n",
    "    \"Zurich,Switzerland\": \"be1ac363913afba07be684e70dcbb7b7dcfd2ba1\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aee47f3-41ef-4091-88c7-f541c8cdc32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_website_data(locations, year:int, month:int, day:int) -> pd.DataFrame:\n",
    "    \"\"\"Access the website with the needed parameters; return a PandasDataFrame\"\"\"\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for location, authority in locations.items():\n",
    "    \n",
    "        async with httpx.AsyncClient() as client:\n",
    "            result = await client.post(\n",
    "                url=\"https://www.wetter2.com/v1/past-weather/\",\n",
    "                headers={\n",
    "                    \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "                    \"Authority\": authority,\n",
    "                },\n",
    "                data={\n",
    "                    \"place\": location,\n",
    "                    \"day\": day,\n",
    "                    \"month\": month,\n",
    "                    \"city\": location.split(',')[0].replace('_', ' '),\n",
    "                    \"country\": location.split(',')[1],\n",
    "                    \"language\": \"german\"\n",
    "                },\n",
    "            )\n",
    "            result.raise_for_status()\n",
    "            result_json = result.json()\n",
    "            result_years = result_json['data']['years']\n",
    "\n",
    "            # Error, if the result is not in the form of a dictionary\n",
    "            if not isinstance(result_years, dict):\n",
    "                raise ValueError(f\"Cannot parse data for {day=} {month=}: {str(res_years)[:50]}...\")\n",
    "\n",
    "            for k, v in result_years.items():\n",
    "                if int(k)!=year:\n",
    "                    continue\n",
    "                date = datetime.date(year=year, month=month, day=day)\n",
    "                if v.get(\"table\") is None:\n",
    "                    continue\n",
    "                res_table = v[\"table\"]\n",
    "    \n",
    "                soup = bs4.BeautifulSoup(res_table)\n",
    "                head = soup.table.thead\n",
    "    \n",
    "                # Create Index\n",
    "                timestamps = []\n",
    "                for td in head.find_all(\"td\"):\n",
    "                    dt = datetime.datetime.combine(date, datetime.time.fromisoformat(td.text))\n",
    "                    dt = pd.Timestamp(dt).tz_localize(\"UTC\")\n",
    "                    timestamps.append(dt)\n",
    "                index = pd.MultiIndex.from_frame(pd.DataFrame(data={\"location\": location, \"datetime\": timestamps}))\n",
    "    \n",
    "    \n",
    "                # Get the data of the html-body and create a dictionary with Temperature, Rain, Wind and Cloudiness\n",
    "                body = soup.table.tbody\n",
    "                data = dict(\n",
    "                    temp_C=[float(span[\"data-temp\"]) for span in body.find(\"th\", string=\"Temperatur\").parent.find_all(\"span\", class_=\"day_temp\")],\n",
    "                    rain_mm=[float(span[\"data-length\"]) for span in body.find(\"th\", string=\"Niederschlag\").parent.find_all(\"span\", attrs={\"data-length\": True})],\n",
    "                    wind_kmh=[float(span[\"data-wind\"]) for span in body.find(\"th\", string=\"Wind\").parent.find_all(\"span\", class_=\"day_wind\")],\n",
    "                    cloud_percent=[float(td.text.strip(\"%\")) for td in body.find(\"th\", string=\"Wolkendecke\").parent.find_all(\"td\")]                                         \n",
    "                )\n",
    "\n",
    "                result = pd.DataFrame(data=data, index=index)\n",
    "                results.append(result)\n",
    "\n",
    "\n",
    "    if results: \n",
    "        # Concate the list-entries to a Dataframe\n",
    "        return pd.concat(results)\n",
    "    \n",
    "    else:\n",
    "        # Return empty dataframe, if there is no data\n",
    "        data = dict(\n",
    "            location = pd.Series([], dtype=str),\n",
    "            datetime = pd.Series([], dtype=\"M8[ns]\"), # M8 is Timestamp\n",
    "            temp_C=pd.Series([], dtype=float),\n",
    "            rain_mm=pd.Series([], dtype=float),\n",
    "            wind_kmh=pd.Series([], dtype=float),\n",
    "            cloud_percent=pd.Series([], dtype=float),                                        \n",
    "        )\n",
    "        return pd.DataFrame(data=data).set_index([\"location\", \"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adaa3ece-4292-42f5-bb0c-4738bd3f0989",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scraping():\n",
    "    \"\"\"Run the program: Scraping the website\"\"\"\n",
    "    \n",
    "    date = pd.date_range(start_date, end_date, freq=\"D\")\n",
    "\n",
    "    collected_dfs = []\n",
    "    \n",
    "    for d in date:\n",
    "        print(f'Working on {d.year}-{d.month}-{d.day}')\n",
    "        try:\n",
    "            df = await scrape_website_data(locations=locations, year=d.year, month=d.month, day=d.day)\n",
    "            collected_dfs.append(df)\n",
    "        except Exception as ex:\n",
    "            print(f'Problem with {d.year}-{d.month}-{d.day}')\n",
    "            pass\n",
    "            \n",
    "    df_to_insert = pd.concat(collected_dfs)  \n",
    "\n",
    "    print(\"all data scraped, ready to insert in db\")\n",
    "\n",
    "    return df_to_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5965d55b-b2b4-4e0e-b05a-af322383da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def inserting_raw_data(df_to_insert):\n",
    "    \"\"\"Run the program: Insert the data to the collection;\n",
    "    if there is already a data-set with the same location and time,\n",
    "    an error is raised and ignored, but the rest of the inserts will carry on\"\"\"\n",
    "\n",
    "    collection = connect_to_db_Wetter()\n",
    "    \n",
    "    try:\n",
    "        data = df_to_insert.reset_index().to_dict(\"records\")\n",
    "\n",
    "        collection.insert_many(\n",
    "            data,\n",
    "            ordered=False,\n",
    "        )\n",
    "        \n",
    "    except pymongo.errors.BulkWriteError as ex:\n",
    "        result = dict(ex.details)\n",
    "        write_errors = result.pop(\"writeErrors\",[])\n",
    "        ok = all(err.get(\"code\") == 11000 for err in write_errors)\n",
    "        ok = ok and not result.get(\"writeConcernErrors\")\n",
    "        n_success = result['nInserted']\n",
    "        n_duplicate = len(write_errors)\n",
    "        ok = ok and (n_success + n_duplicate) == df_to_insert.shape[0]\n",
    "        if ok:\n",
    "            print(f\"Discarded {n_duplicate} inserts due to duplicate keys, inserted {n_success} documents.\")\n",
    "        else:\n",
    "            had_write_concern = len(result.get(\"writeConcernErrors\",[]))\n",
    "            not_discarded = sum(err.get(\"code\") != 11000 for err in write_errors)\n",
    "            raise RuntimeError(f\"Unexpected error; {n_duplicate=} {n_success=} {df_to_insert.shape[0]=} {had_write_concern=} {not_discarded=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab487e01-8ae1-40b1-838e-c0eb82495557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_hourly_weather():\n",
    "\n",
    "    collection = connect_to_db_Wetter()\n",
    "\n",
    "    start_datetime = datetime.datetime.combine(start_date, datetime.datetime.min.time()).replace(tzinfo=datetime.timezone.utc)\n",
    "\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$match\": {\n",
    "                \"datetime\": {\"$gt\": start_datetime}\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            '$addFields': {\n",
    "                'date': {\n",
    "                    '$substr': [\n",
    "                        '$datetime', 0, 10\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }, \n",
    "        {\n",
    "            '$group': {\n",
    "                '_id': '$date', \n",
    "                'avg_temp': {\n",
    "                    '$avg': '$temp_C'\n",
    "                }, \n",
    "                'min_temp': {\n",
    "                    '$min': '$temp_C'\n",
    "                }, \n",
    "                'max_temp': {\n",
    "                    '$max': '$temp_C'\n",
    "                }, \n",
    "                'rain': {\n",
    "                    '$avg': '$rain_mm'\n",
    "                }, \n",
    "                'wind_speed': {\n",
    "                    '$avg': '$wind_kmh'\n",
    "                }, \n",
    "                'clouds': {\n",
    "                    '$avg': '$cloud_percent'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    for x in collection.aggregate(pipeline):\n",
    "        results.append(x)\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df = df.set_index(\"_id\")\n",
    "    df = df.sort_index()\n",
    "    df.index = df.index.rename(\"date\")\n",
    "    df[\"wind_speed\"] /= 3.6\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e09b9d47-e477-4115-9d52-cb412362e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_transformed_data_to_db(df):\n",
    "    \"\"\"Insert the data to the collection; if there is already a data-set with the same location and time,\n",
    "    an Error is raised, but the rest of the inserts will carry on\"\"\"\n",
    "    \n",
    "    collection = connect_to_db_Wetter_Durchschnitt()\n",
    "    \n",
    "    data = df.reset_index().to_dict(\"records\")\n",
    "\n",
    "    bulk_operations = []\n",
    "    \n",
    "    for d in data:\n",
    "        filter_query = {\"date\": d[\"date\"]}\n",
    "        update_query = {\"$set\": d}\n",
    "        bulk_operations.append(pymongo.UpdateOne(filter_query, update_query, upsert=True))\n",
    "    \n",
    "    if bulk_operations:\n",
    "        collection.bulk_write(bulk_operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "693db817-407b-486d-9a6c-a5f5e396d97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 2022-2-8\n",
      "Working on 2022-2-9\n",
      "Working on 2022-2-10\n",
      "Working on 2022-2-11\n",
      "Working on 2022-2-12\n",
      "Working on 2022-2-13\n",
      "Working on 2022-2-14\n",
      "Working on 2022-2-15\n",
      "Working on 2022-2-16\n",
      "Working on 2022-2-17\n",
      "Working on 2022-2-18\n",
      "Working on 2022-2-19\n",
      "Working on 2022-2-20\n",
      "Working on 2022-2-21\n",
      "Working on 2022-2-22\n",
      "Working on 2022-2-23\n",
      "Working on 2022-2-24\n",
      "Working on 2022-2-25\n",
      "Working on 2022-2-26\n",
      "Working on 2022-2-27\n",
      "Working on 2022-2-28\n",
      "Working on 2022-3-1\n",
      "Working on 2022-3-2\n",
      "Working on 2022-3-3\n",
      "Working on 2022-3-4\n",
      "Working on 2022-3-5\n",
      "Working on 2022-3-6\n",
      "Working on 2022-3-7\n",
      "Working on 2022-3-8\n",
      "Working on 2022-3-9\n",
      "Working on 2022-3-10\n",
      "Working on 2022-3-11\n",
      "Working on 2022-3-12\n",
      "Working on 2022-3-13\n",
      "Working on 2022-3-14\n",
      "Working on 2022-3-15\n",
      "Working on 2022-3-16\n",
      "Working on 2022-3-17\n",
      "Working on 2022-3-18\n",
      "Working on 2022-3-19\n",
      "Working on 2022-3-20\n",
      "Working on 2022-3-21\n",
      "Working on 2022-3-22\n",
      "Working on 2022-3-23\n",
      "Working on 2022-3-24\n",
      "Working on 2022-3-25\n",
      "Working on 2022-3-26\n",
      "Working on 2022-3-27\n",
      "Working on 2022-3-28\n",
      "Working on 2022-3-29\n",
      "Working on 2022-3-30\n",
      "Working on 2022-3-31\n",
      "Working on 2022-4-1\n",
      "Working on 2022-4-2\n",
      "Working on 2022-4-3\n",
      "Working on 2022-4-4\n",
      "Working on 2022-4-5\n",
      "Working on 2022-4-6\n",
      "Working on 2022-4-7\n",
      "Working on 2022-4-8\n",
      "Working on 2022-4-9\n",
      "Working on 2022-4-10\n",
      "Working on 2022-4-11\n",
      "Working on 2022-4-12\n",
      "Working on 2022-4-13\n",
      "Working on 2022-4-14\n",
      "Working on 2022-4-15\n",
      "Working on 2022-4-16\n",
      "Working on 2022-4-17\n",
      "Working on 2022-4-18\n",
      "Working on 2022-4-19\n",
      "Working on 2022-4-20\n",
      "Working on 2022-4-21\n",
      "Working on 2022-4-22\n",
      "Working on 2022-4-23\n",
      "Working on 2022-4-24\n",
      "Working on 2022-4-25\n",
      "Working on 2022-4-26\n",
      "Working on 2022-4-27\n",
      "Working on 2022-4-28\n",
      "Working on 2022-4-29\n",
      "Working on 2022-4-30\n",
      "Working on 2022-5-1\n",
      "Working on 2022-5-2\n",
      "Working on 2022-5-3\n",
      "Working on 2022-5-4\n",
      "Working on 2022-5-5\n",
      "Working on 2022-5-6\n",
      "Working on 2022-5-7\n",
      "Working on 2022-5-8\n",
      "Working on 2022-5-9\n",
      "Working on 2022-5-10\n",
      "Working on 2022-5-11\n",
      "Working on 2022-5-12\n",
      "Working on 2022-5-13\n",
      "Working on 2022-5-14\n",
      "Working on 2022-5-15\n",
      "Working on 2022-5-16\n",
      "Working on 2022-5-17\n",
      "Working on 2022-5-18\n",
      "Working on 2022-5-19\n",
      "all data scraped, ready to insert in db\n"
     ]
    }
   ],
   "source": [
    "df_raw = await scraping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1528813a-7593-4751-98fc-3882d1c31fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded 9504 inserts due to duplicate keys, inserted 69816 documents.\n"
     ]
    }
   ],
   "source": [
    "await inserting_raw_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afa3ebbf-5191-4b2a-a283-cfcb86c85b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = transform_hourly_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42c0ae8f-b0cb-413e-8657-6247c6d4c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_transformed_data_to_db(df_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453e5f2-c8e1-4138-8bc9-02fb192ae8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "761ab305-62c9-43ba-93cb-016e62b28499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>rain</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>clouds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-08</th>\n",
       "      <td>-1.181940</td>\n",
       "      <td>-17.1</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.498003</td>\n",
       "      <td>9.819398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-09</th>\n",
       "      <td>0.629327</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.420094</td>\n",
       "      <td>5.650641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-10</th>\n",
       "      <td>0.871474</td>\n",
       "      <td>-10.9</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.084446</td>\n",
       "      <td>6.668269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-11</th>\n",
       "      <td>-1.042788</td>\n",
       "      <td>-16.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.127356</td>\n",
       "      <td>2.197516</td>\n",
       "      <td>69.785256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-12</th>\n",
       "      <td>-3.485577</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>2.165465</td>\n",
       "      <td>16.623397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-13</th>\n",
       "      <td>3.295486</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.518715</td>\n",
       "      <td>1.755691</td>\n",
       "      <td>80.479167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14</th>\n",
       "      <td>4.575231</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>1.466049</td>\n",
       "      <td>37.650463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-15</th>\n",
       "      <td>5.849306</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.318750</td>\n",
       "      <td>1.725823</td>\n",
       "      <td>73.130787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-16</th>\n",
       "      <td>5.925347</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.204931</td>\n",
       "      <td>2.470711</td>\n",
       "      <td>71.378472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-17</th>\n",
       "      <td>5.232176</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.018669</td>\n",
       "      <td>1.193898</td>\n",
       "      <td>64.430556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>764 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            avg_temp  min_temp  max_temp      rain  wind_speed     clouds\n",
       "date                                                                     \n",
       "2022-02-08 -1.181940     -17.1      11.9  0.000000    1.498003   9.819398\n",
       "2022-02-09  0.629327      -8.1      13.9  0.000000    1.420094   5.650641\n",
       "2022-02-10  0.871474     -10.9      13.3  0.000000    2.084446   6.668269\n",
       "2022-02-11 -1.042788     -16.9      10.8  0.127356    2.197516  69.785256\n",
       "2022-02-12 -3.485577     -19.5       8.7  0.000096    2.165465  16.623397\n",
       "...              ...       ...       ...       ...         ...        ...\n",
       "2024-03-13  3.295486      -7.1      14.9  0.518715    1.755691  80.479167\n",
       "2024-03-14  4.575231      -6.5      16.6  0.000938    1.466049  37.650463\n",
       "2024-03-15  5.849306      -4.9      15.3  0.318750    1.725823  73.130787\n",
       "2024-03-16  5.925347      -5.8      18.6  0.204931    2.470711  71.378472\n",
       "2024-03-17  5.232176      -6.3      15.8  0.018669    1.193898  64.430556\n",
       "\n",
       "[764 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d4971-2693-420d-b58c-8c59dcde5588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ad003-0933-496f-949b-69de9a9bceca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
